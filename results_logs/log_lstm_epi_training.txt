/home/skatta14/tcr_receptor/models/catELMo_lstm_epi.hdf5
================check Overlapping========================
number of overlapping tcrs:  749
number of overlapping epitopes:  0
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
dense (Dense)                   (None, 2048)         4196352     input_1[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2048)         4196352     input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 2048)         8192        dense_1[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 2048)         0           batch_normalization[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2048)         0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
tf.nn.silu (TFOpLambda)         (None, 2048)         0           dropout[0][0]                    
__________________________________________________________________________________________________
tf.nn.silu_1 (TFOpLambda)       (None, 2048)         0           dropout_1[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 4096)         0           tf.nn.silu[0][0]                 
                                                                 tf.nn.silu_1[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1024)         4195328     concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 1024)         4096        dense_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 1024)         0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
tf.nn.silu_2 (TFOpLambda)       (None, 1024)         0           dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            1025        tf.nn.silu_2[0][0]               
==================================================================================================
Total params: 12,609,537
Trainable params: 12,599,297
Non-trainable params: 10,240
__________________________________________________________________________________________________
Epoch 00117: early stopping
================Performance========================
catELMo_lstm_epi_epi_seed_42_fraction_1.0AUC: 0.9920726589155374
precision_recall_fscore_macro (0.960526211628238, 0.9575750482766692, 0.9575069718761681, None)
acc is 0.9575750482766692
precision1 is 0.9973920234081801
precision0 is 0.9236603998482961
recall1 is 0.9175493007197613
recall0 is 0.9976007958335772
f1macro is 0.9575069718761681
f1micro is 0.9575750482766692
/home/skatta14/tcr_receptor/models/catELMo_lstm_epi.hdf5
================check Overlapping========================
number of overlapping tcrs:  749
number of overlapping epitopes:  0
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
dense (Dense)                   (None, 2048)         4196352     input_1[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2048)         4196352     input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 2048)         8192        dense_1[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 2048)         0           batch_normalization[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2048)         0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
tf.nn.silu (TFOpLambda)         (None, 2048)         0           dropout[0][0]                    
__________________________________________________________________________________________________
tf.nn.silu_1 (TFOpLambda)       (None, 2048)         0           dropout_1[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 4096)         0           tf.nn.silu[0][0]                 
                                                                 tf.nn.silu_1[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1024)         4195328     concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 1024)         4096        dense_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 1024)         0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
tf.nn.silu_2 (TFOpLambda)       (None, 1024)         0           dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            1025        tf.nn.silu_2[0][0]               
==================================================================================================
Total params: 12,609,537
Trainable params: 12,599,297
Non-trainable params: 10,240
__________________________________________________________________________________________________
Epoch 00099: early stopping
================Performance========================
catELMo_lstm_epi_epi_seed_42_fraction_1.0AUC: 0.9946002796709359
precision_recall_fscore_macro (0.9614065405312902, 0.9585990988355082, 0.9585360266434996, None)
acc is 0.9585990988355082
precision1 is 0.9973978167047474
precision0 is 0.9254152643578331
recall1 is 0.9195974018374393
recall0 is 0.9976007958335772
f1macro is 0.9585360266434996
f1micro is 0.9585990988355081
/home/skatta14/tcr_receptor/models/catELMo_lstm_epi.hdf5
================check Overlapping========================
number of overlapping tcrs:  749
number of overlapping epitopes:  0
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
dense (Dense)                   (None, 2048)         4196352     input_1[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2048)         4196352     input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 2048)         8192        dense_1[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 2048)         0           batch_normalization[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2048)         0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
tf.nn.silu (TFOpLambda)         (None, 2048)         0           dropout[0][0]                    
__________________________________________________________________________________________________
tf.nn.silu_1 (TFOpLambda)       (None, 2048)         0           dropout_1[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 4096)         0           tf.nn.silu[0][0]                 
                                                                 tf.nn.silu_1[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1024)         4195328     concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 1024)         4096        dense_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 1024)         0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
tf.nn.silu_2 (TFOpLambda)       (None, 1024)         0           dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            1025        tf.nn.silu_2[0][0]               
==================================================================================================
Total params: 12,609,537
Trainable params: 12,599,297
Non-trainable params: 10,240
__________________________________________________________________________________________________
Epoch 00063: early stopping
================Performance========================
catELMo_lstm_epi_epi_seed_42_fraction_1.0AUC: 0.9933253301762847
precision_recall_fscore_macro (0.9648943086579211, 0.9629293697700274, 0.9628901573234343, None)
acc is 0.9629293697700275
precision1 is 0.9951182876455126
precision0 is 0.9346703296703297
recall1 is 0.9304230791737375
recall0 is 0.9954356603663175
f1macro is 0.9628901573234343
f1micro is 0.9629293697700275
/home/skatta14/tcr_receptor/models/catELMo_lstm_epi.hdf5
================check Overlapping========================
number of overlapping tcrs:  749
number of overlapping epitopes:  0
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
dense (Dense)                   (None, 2048)         4196352     input_1[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2048)         4196352     input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 2048)         8192        dense_1[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 2048)         0           batch_normalization[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2048)         0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
tf.nn.silu (TFOpLambda)         (None, 2048)         0           dropout[0][0]                    
__________________________________________________________________________________________________
tf.nn.silu_1 (TFOpLambda)       (None, 2048)         0           dropout_1[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 4096)         0           tf.nn.silu[0][0]                 
                                                                 tf.nn.silu_1[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1024)         4195328     concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 1024)         4096        dense_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 1024)         0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
tf.nn.silu_2 (TFOpLambda)       (None, 1024)         0           dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            1025        tf.nn.silu_2[0][0]               
==================================================================================================
Total params: 12,609,537
Trainable params: 12,599,297
Non-trainable params: 10,240
__________________________________________________________________________________________________
Epoch 00089: early stopping
================Performance========================
catELMo_lstm_epi_epi_seed_42_fraction_1.0AUC: 0.9942911922892683
precision_recall_fscore_macro (0.9688894339516372, 0.9673474164667331, 0.9673205485732339, None)
acc is 0.967347416466733
precision1 is 0.9957787572164628
precision0 is 0.9420001106868117
recall1 is 0.9386740008192405
recall0 is 0.9960208321142255
f1macro is 0.9673205485732339
f1micro is 0.967347416466733
/home/skatta14/tcr_receptor/models/catELMo_lstm_epi.hdf5
================check Overlapping========================
number of overlapping tcrs:  749
number of overlapping epitopes:  0
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
dense (Dense)                   (None, 2048)         4196352     input_1[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2048)         4196352     input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 2048)         8192        dense_1[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 2048)         0           batch_normalization[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2048)         0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
tf.nn.silu (TFOpLambda)         (None, 2048)         0           dropout[0][0]                    
__________________________________________________________________________________________________
tf.nn.silu_1 (TFOpLambda)       (None, 2048)         0           dropout_1[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 4096)         0           tf.nn.silu[0][0]                 
                                                                 tf.nn.silu_1[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1024)         4195328     concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 1024)         4096        dense_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 1024)         0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
tf.nn.silu_2 (TFOpLambda)       (None, 1024)         0           dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            1025        tf.nn.silu_2[0][0]               
==================================================================================================
Total params: 12,609,537
Trainable params: 12,599,297
Non-trainable params: 10,240
__________________________________________________________________________________________________
Epoch 00105: early stopping
================Performance========================
catELMo_lstm_epi_epi_seed_42_fraction_1.0AUC: 0.9932988692091013
precision_recall_fscore_macro (0.95825936147756, 0.9547662238867107, 0.9546798593187695, None)
acc is 0.9547662238867107
precision1 is 0.9982688978649741
precision0 is 0.9182498250901459
recall1 is 0.9111124114927731
recall0 is 0.9984200362806483
f1macro is 0.9546798593187695
f1micro is 0.9547662238867107
